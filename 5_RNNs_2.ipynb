{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJNqgMl-qxYd"
      },
      "source": [
        "RNNs_2\n",
        "\n",
        "\n",
        "1.   Shashankh Mysore Girish\n",
        "2.   Roshan Rayala Bhaskar\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "snZVFgU91tAW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umqeq6w632Ng",
        "outputId": "a5ec832e-6805-4902-fc0e-fc1ed49a9d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "(train_sequences, train_labels), (test_sequences, test_labels) = tf.keras.datasets.imdb.load_data(num_words=max_words)\n",
        "\n",
        "\n",
        "def preprocess(sequences, labels):\n",
        "    return sequences, labels.astype(np.int32)\n",
        "\n",
        "train_sequences, train_labels = preprocess(train_sequences, train_labels)\n",
        "test_sequences, test_labels = preprocess(test_sequences, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHJA6HJm33km",
        "outputId": "e0742a0d-30ad-417a-8ca8-45602f6de08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vocabulary = tf.keras.datasets.imdb.get_word_index()\n",
        "char_to_ind = vocabulary\n",
        "ind_to_char = {ind: char for (char, ind) in vocabulary.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "s5fercgq35v5",
        "outputId": "733b79f0-ec72-4135-a128-ee4fe9574bab"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1c04c7829a62>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# remember this? doesn't work...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensor_slices_op.py\u001b[0m in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_TensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensor_slices_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    132\u001b[0m           \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m           normalized_components.append(\n\u001b[0;32m--> 134\u001b[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i, dtype=dtype))\n\u001b[0m\u001b[1;32m    135\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpack_as\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    696\u001b[0m   \u001b[0;31m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0mpreferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m   return tensor_conversion_registry.convert(\n\u001b[0m\u001b[1;32m    699\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted_result_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    326\u001b[0m                                          as_ref=False):\n\u001b[1;32m    327\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;31m# Register the conversion function for the \"unconvertible\" types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    268\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m         pywrap_tfe.TFE_ContextOptionsSetJitCompileRewrite(\n\u001b[1;32m    597\u001b[0m             opts, self._jit_compile_rewrite)\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# remember this? doesn't work...\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_sequences, train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vxmJFX1B4MZ4"
      },
      "outputs": [],
      "source": [
        "# we can create a dataset from a python generator. first, we have to write the generator\n",
        "# this is a very simple one, but we could execute arbitrary python code in here\n",
        "# (say, loading files from disk and preparing the loaded inputs somehow)\n",
        "def gen():\n",
        "    for sequence, label in zip(train_sequences, train_labels):\n",
        "        yield sequence, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Lq6XE4j4gay"
      },
      "outputs": [],
      "source": [
        "# we have to tell TF what to expect from the generator (\"Tensor Specification\")\n",
        "train_data = tf.data.Dataset.from_generator(gen, output_signature=(\n",
        "         tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
        "         tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
        "\n",
        "# regular .batch wouldn't work because the inputs are different length\n",
        "# padded batch automatically pads all elements in the batch to the longest length\n",
        "# per dimension.\n",
        "# you can also specify different shapes and padding values other than 0.\n",
        "# padding is always \"post\"\n",
        "train_data = train_data.shuffle(25000).padded_batch(32).repeat(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hUx7O2Ha4ifV"
      },
      "outputs": [],
      "source": [
        "lengths = []\n",
        "for sequence, label in train_data:\n",
        "    lengths.append(sequence.shape[1])\n",
        "    #print(sequence.shape, label.shape)\n",
        "    #input()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "sZ5LUbTpoZVG",
        "outputId": "55c5682c-c524-45b8-b831-ed5c0802a559"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "794.4920716112532\n"
          ]
        }
      ],
      "source": [
        "plt.hist(lengths, bins=100)\n",
        "plt.show()\n",
        "\n",
        "print(np.mean(lengths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVgxkqBIoXWe"
      },
      "outputs": [],
      "source": [
        "# we have to tell TF what to expect from the generator (\"Tensor Specification\")\n",
        "train_data = tf.data.Dataset.from_generator(gen, output_signature=(\n",
        "         tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
        "         tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
        "\n",
        "# alternatively, we can use bucketing. the idea is to define buckets for specific\n",
        "# sequence lengths, and put all sequences in their corresponding bucket.\n",
        "# when a batch is requested, first a bucket is selected and then all elements of\n",
        "# the batch are taken from this bucket.\n",
        "# this guarantees that all elements in a batch are roughly the same length,\n",
        "# minimizing the amount of padding.\n",
        "\n",
        "# here is an example with buckets in steps of 50. all sequences above length 500\n",
        "# end up in the same bucket. same for sequences below length 50.\n",
        "# do note that I by no means claim that this is a \"good\" bucketing. play around with it!\n",
        "buckets = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
        "bucket_batch_size = [32] * (len(buckets) + 1)\n",
        "train_data = train_data.bucket_by_sequence_length(lambda sequence, label: tf.shape(sequence)[0],\n",
        "                                                  bucket_boundaries=buckets, bucket_batch_sizes=bucket_batch_size).repeat(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGeoD0PforFO"
      },
      "outputs": [],
      "source": [
        "lengths = []\n",
        "for sequence, label in train_data:\n",
        "    lengths.append(sequence.shape[1])\n",
        "    #print(sequence.shape, label.shape)\n",
        "    #input()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "rqJ5h4TNotLl",
        "outputId": "8d3cde41-c59c-4422-d77c-70446401173b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "299.38040712468194\n"
          ]
        }
      ],
      "source": [
        "plt.hist(lengths, bins=100)\n",
        "plt.show()\n",
        "\n",
        "print(np.mean(lengths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Bj3tdaWpCZz"
      },
      "outputs": [],
      "source": [
        "# compare the average batch shapes with the padded_batch example. there, batches are\n",
        "# often length 800 or so because the longest sequence in the batch happened to\n",
        "# have that length.\n",
        "# with bucketing, we get many much smaller batches, meaning more efficient training.\n",
        "for sequence, label in train_data:\n",
        "    print(sequence.shape, label.shape)\n",
        "    input()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R5z3NdMAwD9"
      },
      "outputs": [],
      "source": [
        "# here's a very simple toy example for a keras lstm\n",
        "# the \"hidden dimensions\" are just randomly chosen.\n",
        "# you probably don't want to use a hidden size of 12 =) (but maybe it's actually really good?)\n",
        "\n",
        "\n",
        "# embedding comes first to replace one-hot vectors.\n",
        "#    mask_zero=True to prevent computations on padded time steps.\n",
        "# then an arbitrary number of RNN layers.\n",
        "# deeper RNN layers take as input sequence the state sequence of the layer before,\n",
        "# so all layers except the last one should return_sequences=True\n",
        "# finally, a Dense layer for the output, since the output computation is *not*\n",
        "# included in the RNN cells; all cells provided by Keras only compute the states\n",
        "model = tf.keras.Sequential([tf.keras.layers.Embedding(max_words, 20, mask_zero=True),\n",
        "                             tf.keras.layers.LSTM(12, return_sequences=True),\n",
        "                             tf.keras.layers.LSTM(15),\n",
        "                             tf.keras.layers.Dense(1)])\n",
        "\n",
        "\n",
        "# FYI, the third line is the same as the first two lines together.\n",
        "# the second option can use a much more efficient implementation, it will be SOOO much faster.\n",
        "# try it yourself!\n",
        "#rnn_cell = tf.keras.layers.LSTMCell(12)\n",
        "#rnn = tf.keras.layers.RNN(rnn_cell, return_sequences=False)\n",
        "rnn = tf.keras.layers.LSTM(12, return_sequences=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQvxblepEoDt",
        "outputId": "7c51cb53-5213-427f-bfef-c86695c9e28a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
              "array([[-1.3870468e-03],\n",
              "       [-3.0032499e-04],\n",
              "       [-1.0252198e-03],\n",
              "       [ 1.3154706e-03],\n",
              "       [-9.3264505e-04],\n",
              "       [-7.2880718e-04],\n",
              "       [-7.4817752e-03],\n",
              "       [-2.4321130e-03],\n",
              "       [-3.1349901e-04],\n",
              "       [ 7.9292938e-04],\n",
              "       [-3.6126981e-03],\n",
              "       [ 6.3220263e-03],\n",
              "       [ 1.3634494e-03],\n",
              "       [-2.0773998e-03],\n",
              "       [ 1.3722768e-03],\n",
              "       [-4.8380916e-04],\n",
              "       [-1.3174444e-03],\n",
              "       [ 1.8112793e-03],\n",
              "       [-1.9143958e-03],\n",
              "       [ 3.4866042e-03],\n",
              "       [-3.6228197e-03],\n",
              "       [ 7.3302531e-04],\n",
              "       [ 1.8552437e-03],\n",
              "       [-5.2365116e-03],\n",
              "       [ 2.4817719e-03],\n",
              "       [ 7.7644247e-04],\n",
              "       [ 2.7285842e-03],\n",
              "       [ 8.5247064e-04],\n",
              "       [-3.5622229e-03],\n",
              "       [-3.6103823e-03],\n",
              "       [-2.1194906e-03],\n",
              "       [-8.3078630e-05]], dtype=float32)>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# calling RNN layers is easy!\n",
        "# \"sequence\" is defined above from iterating over the data batches\n",
        "model(sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piSLVKmSEyP2",
        "outputId": "f1eb57e9-3cd9-49fb-a2e4-72c57d01223a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "   3930/Unknown - 250s 59ms/step - loss: 0.4391 - accuracy: 0.8137Epoch 1, Accuracy: 81.37%\n",
            "3930/3930 [==============================] - 250s 59ms/step - loss: 0.4391 - accuracy: 0.8137\n",
            "Epoch 2/5\n",
            "3930/3930 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.8556Epoch 2, Accuracy: 85.56%\n",
            "3930/3930 [==============================] - 134s 34ms/step - loss: 0.3395 - accuracy: 0.8556\n",
            "Epoch 3/5\n",
            "3929/3930 [============================>.] - ETA: 0s - loss: 0.3238 - accuracy: 0.8710Epoch 3, Accuracy: 87.10%\n",
            "3930/3930 [==============================] - 129s 33ms/step - loss: 0.3237 - accuracy: 0.8710\n",
            "Epoch 4/5\n",
            "3930/3930 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9276Epoch 4, Accuracy: 92.76%\n",
            "3930/3930 [==============================] - 127s 32ms/step - loss: 0.2078 - accuracy: 0.9276\n",
            "Epoch 5/5\n",
            "3929/3930 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9287Epoch 5, Accuracy: 92.87%\n",
            "3930/3930 [==============================] - 147s 37ms/step - loss: 0.2297 - accuracy: 0.9287\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a8cb5232e00>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class PrintAccuracyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f'Epoch {epoch + 1}, Accuracy: {logs[\"accuracy\"] * 100:.2f}%')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the callback\n",
        "model.fit(train_data, epochs=5, callbacks=[PrintAccuracyCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4ZdWFmeSpGe"
      },
      "source": [
        "Now let us change the bucket size and bucket batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yf5iTHMbSuFG"
      },
      "outputs": [],
      "source": [
        "# we have to tell TF what to expect from the generator (\"Tensor Specification\")\n",
        "train_data = tf.data.Dataset.from_generator(gen, output_signature=(\n",
        "         tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
        "         tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
        "\n",
        "\n",
        "buckets = [200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100]\n",
        "bucket_batch_size = [32] * (len(buckets) + 1)\n",
        "train_data = train_data.bucket_by_sequence_length(lambda sequence, label: tf.shape(sequence)[0],\n",
        "                                                  bucket_boundaries=buckets, bucket_batch_sizes=bucket_batch_size).repeat(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZJHDl42UGBe",
        "outputId": "7710cf2c-4028-4fb9-e279-8abcb4236d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "   3940/Unknown - 230s 52ms/step - loss: 0.4348 - accuracy: 0.8202Epoch 1, Accuracy: 82.02%\n",
            "3940/3940 [==============================] - 230s 52ms/step - loss: 0.4348 - accuracy: 0.8202\n",
            "Epoch 2/5\n",
            "3940/3940 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.8913Epoch 2, Accuracy: 89.13%\n",
            "3940/3940 [==============================] - 130s 33ms/step - loss: 0.2779 - accuracy: 0.8913\n",
            "Epoch 3/5\n",
            "3940/3940 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.8918Epoch 3, Accuracy: 89.18%\n",
            "3940/3940 [==============================] - 129s 33ms/step - loss: 0.2812 - accuracy: 0.8918\n",
            "Epoch 4/5\n",
            "3940/3940 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9233Epoch 4, Accuracy: 92.33%\n",
            "3940/3940 [==============================] - 133s 34ms/step - loss: 0.2214 - accuracy: 0.9233\n",
            "Epoch 5/5\n",
            "3940/3940 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9447Epoch 5, Accuracy: 94.47%\n",
            "3940/3940 [==============================] - 137s 35ms/step - loss: 0.1808 - accuracy: 0.9447\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a8cb6b1c640>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# here's a very simple toy example for a keras lstm\n",
        "# the \"hidden dimensions\" are just randomly chosen.\n",
        "# you probably don't want to use a hidden size of 12 =) (but maybe it's actually really good?)\n",
        "\n",
        "\n",
        "# embedding comes first to replace one-hot vectors.\n",
        "#    mask_zero=True to prevent computations on padded time steps.\n",
        "# then an arbitrary number of RNN layers.\n",
        "# deeper RNN layers take as input sequence the state sequence of the layer before,\n",
        "# so all layers except the last one should return_sequences=True\n",
        "# finally, a Dense layer for the output, since the output computation is *not*\n",
        "# included in the RNN cells; all cells provided by Keras only compute the states\n",
        "model = tf.keras.Sequential([tf.keras.layers.Embedding(max_words, 20, mask_zero=True),\n",
        "                             tf.keras.layers.LSTM(12, return_sequences=True),\n",
        "                             tf.keras.layers.LSTM(15),\n",
        "                             tf.keras.layers.Dense(1)])\n",
        "\n",
        "\n",
        "# FYI, the third line is the same as the first two lines together.\n",
        "# the second option can use a much more efficient implementation, it will be SOOO much faster.\n",
        "# try it yourself!\n",
        "#rnn_cell = tf.keras.layers.LSTMCell(12)\n",
        "#rnn = tf.keras.layers.RNN(rnn_cell, return_sequences=False)\n",
        "rnn = tf.keras.layers.LSTM(12, return_sequences=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# calling RNN layers is easy!\n",
        "# \"sequence\" is defined above from iterating over the data batches\n",
        "model(sequence)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PrintAccuracyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f'Epoch {epoch + 1}, Accuracy: {logs[\"accuracy\"] * 100:.2f}%')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the callback\n",
        "model.fit(train_data, epochs=5, callbacks=[PrintAccuracyCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrgFKlS2h2CK"
      },
      "source": [
        "Lets change the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiNw4aObh5JZ",
        "outputId": "b17bc5ec-bcce-4d96-9656-75272f6d1827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "   3910/Unknown - 437s 106ms/step - loss: 0.4125 - accuracy: 0.8291Epoch 1, Accuracy: 82.91%\n",
            "3910/3910 [==============================] - 437s 106ms/step - loss: 0.4125 - accuracy: 0.8291\n",
            "Epoch 2/5\n",
            "3910/3910 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.8257Epoch 2, Accuracy: 82.57%\n",
            "3910/3910 [==============================] - 322s 81ms/step - loss: 0.4250 - accuracy: 0.8257\n",
            "Epoch 3/5\n",
            "3910/3910 [==============================] - ETA: 0s - loss: 0.2967 - accuracy: 0.8895Epoch 3, Accuracy: 88.95%\n",
            "3910/3910 [==============================] - 328s 83ms/step - loss: 0.2967 - accuracy: 0.8895\n",
            "Epoch 4/5\n",
            "3910/3910 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.9421Epoch 4, Accuracy: 94.21%\n",
            "3910/3910 [==============================] - 323s 81ms/step - loss: 0.1841 - accuracy: 0.9421\n",
            "Epoch 5/5\n",
            "3910/3910 [==============================] - ETA: 0s - loss: 0.1567 - accuracy: 0.9562Epoch 5, Accuracy: 95.62%\n",
            "3910/3910 [==============================] - 333s 84ms/step - loss: 0.1567 - accuracy: 0.9562\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79618faa0f10>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# here's a very simple toy example for a keras lstm\n",
        "# the \"hidden dimensions\" are just randomly chosen.\n",
        "# you probably don't want to use a hidden size of 12 =) (but maybe it's actually really good?)\n",
        "\n",
        "\n",
        "# embedding comes first to replace one-hot vectors.\n",
        "#    mask_zero=True to prevent computations on padded time steps.\n",
        "# then an arbitrary number of RNN layers.\n",
        "# deeper RNN layers take as input sequence the state sequence of the layer before,\n",
        "# so all layers except the last one should return_sequences=True\n",
        "# finally, a Dense layer for the output, since the output computation is *not*\n",
        "# included in the RNN cells; all cells provided by Keras only compute the states\n",
        "model = tf.keras.Sequential([tf.keras.layers.Embedding(max_words, 20, mask_zero=True),\n",
        "                             tf.keras.layers.LSTM(12, return_sequences=True),\n",
        "                             tf.keras.layers.LSTM(15, return_sequences=True),\n",
        "                             tf.keras.layers.LSTM(15, return_sequences=False),\n",
        "                             tf.keras.layers.Dense(1)])\n",
        "\n",
        "\n",
        "# FYI, the third line is the same as the first two lines together.\n",
        "# the second option can use a much more efficient implementation, it will be SOOO much faster.\n",
        "# try it yourself!\n",
        "#rnn_cell = tf.keras.layers.LSTMCell(12)\n",
        "#rnn = tf.keras.layers.RNN(rnn_cell, return_sequences=False)\n",
        "rnn = tf.keras.layers.LSTM(12, return_sequences=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# calling RNN layers is easy!\n",
        "# \"sequence\" is defined above from iterating over the data batches\n",
        "model(sequence)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PrintAccuracyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f'Epoch {epoch + 1}, Accuracy: {logs[\"accuracy\"] * 100:.2f}%')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the callback\n",
        "model.fit(train_data, epochs=5, callbacks=[PrintAccuracyCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0p5zlMsBpZBN"
      },
      "outputs": [],
      "source": [
        "# we can create a dataset from a python generator. first, we have to write the generator\n",
        "# this is a very simple one, but we could execute arbitrary python code in here\n",
        "# (say, loading files from disk and preparing the loaded inputs somehow)\n",
        "def gen_test():\n",
        "    for sequence, label in zip(test_sequences, test_labels):\n",
        "        yield sequence, label\n",
        "\n",
        "\n",
        "# we have to tell TF what to expect from the generator (\"Tensor Specification\")\n",
        "test_data = tf.data.Dataset.from_generator(gen_test, output_signature=(\n",
        "         tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
        "         tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
        "\n",
        "# regular .batch wouldn't work because the inputs are different length\n",
        "# padded batch automatically pads all elements in the batch to the longest length\n",
        "# per dimension.\n",
        "# you can also specify different shapes and padding values other than 0.\n",
        "# padding is always \"post\"\n",
        "test_data = test_data.shuffle(25000).padded_batch(32).repeat(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbxDwgNao58u",
        "outputId": "efcc33cd-84a2-4a7a-e88c-ddf7762c73d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3910/3910 [==============================] - 137s 34ms/step - loss: 1.2279 - accuracy: 0.8526\n",
            "Test Loss: 1.2279\n",
            "Test Accuracy: 85.26%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
